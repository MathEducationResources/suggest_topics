{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict the topic of a Math Question on Math Education Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use **Machine Learning** to predict the topic of a Math Question from the [Math Education Resources](http://math-education-resources.com). For simplicity we will only consider two topics. Using [multiclass classification](https://en.wikipedia.org/wiki/Multiclass_classification) this can be extended to more than two topics (at the time of writing, April 2015, we have about 1500 questions with 150 topics on MER)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To Do:\n",
    "\n",
    "1. ~~Fix pca - Alex~~\n",
    "1. get feature importance\n",
    "1. Write convenience functions:\n",
    "  1. text -> topic\n",
    "  2. text -> list of most similar questions (k-nn / cosine dist)  - Alex\n",
    "1. Add the suggested topics to the database for questions w/o a topic\n",
    "1. ~~Re-write train test split to:  - Alex~~\n",
    "      1. Make sure that each topic appears at least once in train AND test (otherwise label_binarizer will remove that column, which leads to problems later in roc)\n",
    "      2. make the code look good / account for errors - Alex\n",
    "1. ~~ROC curve - fix for unbalanced data - Alex~~\n",
    "1. ~~Put classifier predictions on the website - Alex~~\n",
    "1. ~~Edit functions to work for both regular and parent topics - Bernhard~~\n",
    "1. Normalize feature vectors - TF-IDF\n",
    "1. Edit website\n",
    "\n",
    "-----------------------\n",
    "For later:\n",
    "7. Add additional features (course, etc.)\n",
    "    1. graph them\n",
    "8. Put up recommendations on the website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import helpers\n",
    "from pymongo import MongoClient\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "try:\n",
    "    import cPickle as pickle\n",
    "except:\n",
    "    import pickle\n",
    "\n",
    "\n",
    "# machine learning modules\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.decomposition import PCA\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL:\n",
      "## - Topic\n",
      "==========\n",
      " 2 - Linear approximation\n",
      " 3 - Power iteration\n",
      " 1 - Alternating series test\n",
      " 1 - Condition number\n",
      " 2 - Implicit differentiation\n",
      " 5 - Matrix diagonalization\n",
      " 1 - Determinants\n",
      " 1 - Center of mass\n",
      " 2 - Partial fractions\n",
      " 1 - Matrix operations\n",
      "47 - Eigenvalues and eigenvectors\n",
      " 1 - Initial value problem\n",
      " 2 - Random walks\n",
      "37 - Substitution\n",
      " 4 - Expected value and median\n",
      " 4 - Trigonometric integral\n",
      " 2 - Rank and nullity\n",
      " 2 - Reflection\n",
      "51 - Taylor series\n",
      " 4 - Cumulative distribution function\n",
      " 8 - Integration by parts\n",
      " 1 - Matrix similarity\n",
      " 2 - Fundamental theorem of calculus\n",
      " 1 - Linear transformation definition\n",
      " 2 - Lagrange interpolation\n",
      "40 - Probability density function\n"
     ]
    }
   ],
   "source": [
    "# create an array of all topics of interest\n",
    "topic_tags = [\"Eigenvalues_and_eigenvectors\",\n",
    "              \"Probability_density_function\",\n",
    "              \"Taylor_series\",\n",
    "              \"Substitution\",\n",
    "              \"Lagrange_interpolation\"]\n",
    "\n",
    "\n",
    "questions_raw = helpers.get_questions_with_topics(topic_tags)\n",
    "\n",
    "print('TOTAL:\\n## - Topic\\n==========')\n",
    "for topic, count in helpers.count_topics_in_questions(questions_raw).iteritems():\n",
    "    print('%2d - %s' %(count, topic.replace('_', ' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[u'Linear_algebra'], [u'Linear_algebra'], [u'Linear_algebra'], [u'Linear_algebra'], [u'Linear_algebra'], [u'Linear_algebra'], [u'Linear_algebra'], [u'Linear_algebra'], [u'Linear_algebra'], [u'Linear_algebra'], [u'Linear_algebra'], [u'Linear_algebra'], [u'Linear_algebra'], [u'Linear_algebra'], [u'Linear_algebra'], [u'Linear_algebra'], [u'Linear_algebra'], [u'Linear_algebra'], [u'Linear_algebra'], [u'Linear_algebra'], [u'Linear_algebra'], [u'Linear_algebra'], [u'Linear_algebra'], [u'Linear_algebra'], [u'Linear_algebra'], [u'Linear_algebra'], [u'Linear_algebra'], [u'Linear_algebra'], [u'Linear_algebra'], [u'Linear_algebra'], [u'Sequences_and_series'], [u'Integrate'], [u'Integrate'], [u'Integrate'], [u'Sequences_and_series'], [u'Sequences_and_series'], [u'Integrate'], [u'Sequences_and_series'], [u'Integrate'], [u'Probability_and_statistics'], [u'Sequences_and_series'], [u'Integrate'], [u'Sequences_and_series'], [u'Integrate'], [u'Sequences_and_series'], [u'Probability_and_statistics'], [u'Integrate'], [u'Integrate'], [u'Sequences_and_series'], [u'Probability_and_statistics'], [u'Integrate'], [u'Integrate'], [u'Integrate'], [u'Sequences_and_series'], [u'Integrate'], [u'Integrate'], [u'Sequences_and_series'], [u'Integrate'], [u'Integrate'], [u'Sequences_and_series'], [u'Probability_and_statistics'], [u'Probability_and_statistics'], [u'Probability_and_statistics'], [u'Probability_and_statistics'], [u'Integrate', u'Probability_and_statistics'], [u'Integrate'], [u'Sequences_and_series'], [u'Probability_and_statistics'], [u'Probability_and_statistics'], [u'Sequences_and_series'], [u'Integrate'], [u'Integrate'], [u'Integrate', u'Probability_and_statistics'], [u'Probability_and_statistics'], [u'Differentiate', u'Integrate'], [u'Sequences_and_series'], [u'Sequences_and_series'], [u'Probability_and_statistics'], [u'Differentiate', u'Integrate'], [u'Probability_and_statistics'], [u'Integrate'], [u'Sequences_and_series'], [u'Sequences_and_series'], [u'Probability_and_statistics'], [u'Integrate'], [u'Probability_and_statistics'], [u'Sequences_and_series'], [u'Probability_and_statistics'], [u'Differential_equations', u'Sequences_and_series'], [u'Probability_and_statistics'], [u'Integrate'], [u'Integrate'], [u'Sequences_and_series'], [u'Probability_and_statistics'], [u'Sequences_and_series'], [u'Probability_and_statistics'], [u'Applications_of_integration', u'Integrate'], [u'Probability_and_statistics'], [u'Probability_and_statistics'], [u'Sequences_and_series'], [u'Probability_and_statistics'], [u'Probability_and_statistics'], [u'Integrate'], [u'Probability_and_statistics'], [u'Integrate'], [u'Integrate'], [u'Sequences_and_series'], [u'Probability_and_statistics'], [u'Probability_and_statistics'], [u'Integrate'], [u'Sequences_and_series'], [u'Probability_and_statistics'], [u'Probability_and_statistics'], [u'Sequences_and_series'], [u'Probability_and_statistics'], [u'Integrate'], [u'Probability_and_statistics'], [u'Probability_and_statistics'], [u'Probability_and_statistics'], [u'Probability_and_statistics'], [u'Integrate'], [u'Integrate'], [u'Probability_and_statistics'], [u'Sequences_and_series'], [u'Probability_and_statistics'], [u'Sequences_and_series'], [u'Sequences_and_series'], [u'Integrate'], [u'Probability_and_statistics'], [u'Sequences_and_series'], [u'Probability_and_statistics'], [u'Sequences_and_series'], [u'Integrate'], [u'Sequences_and_series'], [u'Sequences_and_series'], [u'Probability_and_statistics'], [u'Sequences_and_series'], [u'Integrate'], [u'Probability_and_statistics'], [u'Differentiate', u'Sequences_and_series'], [u'Differentiate', u'Sequences_and_series'], [u'Sequences_and_series'], [u'Sequences_and_series'], [u'Sequences_and_series'], [u'Differentiate', u'Sequences_and_series'], [u'Differentiate', u'Sequences_and_series'], [u'Sequences_and_series'], [u'Sequences_and_series'], [u'Sequences_and_series'], [u'Sequences_and_series'], [u'Sequences_and_series'], [u'Sequences_and_series'], [u'Sequences_and_series'], [u'Sequences_and_series'], [u'Sequences_and_series'], [u'Sequences_and_series'], [u'Sequences_and_series'], [u'Linear_algebra'], [u'Linear_algebra'], [u'Linear_algebra'], [u'Linear_algebra'], [u'Linear_algebra'], [u'Linear_algebra'], [u'Linear_algebra', u'None'], [u'Linear_algebra'], [u'Linear_algebra'], [u'Linear_algebra', u'Probability_and_statistics'], [u'Linear_algebra'], [u'Linear_algebra'], [u'Linear_algebra'], [u'Linear_algebra'], [u'Linear_algebra', u'Probability_and_statistics'], [u'Linear_algebra'], [u'Linear_algebra'], [u'Linear_algebra'], [u'Linear_algebra']]\n",
      "------------------------------\n",
      "[u'Differentiate', u'Integrate', u'Linear_algebra', u'Probability_and_statistics', u'Sequences_and_series']\n"
     ]
    }
   ],
   "source": [
    "client = MongoClient()\n",
    "questions_collection = client['merdb'].questions\n",
    "topics_collection = client['merdb'].topics\n",
    "\n",
    "topic_to_parent_dict = helpers.get_topic_to_parent_dict()\n",
    "\n",
    "print(helpers.questions_to_parents(questions_raw))\n",
    "print('-' * 30)\n",
    "print(helpers.unique_parents(questions_raw))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question indices for topic Eigenvalues_and_eigenvectors: \n",
      "[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175]\n",
      "------------------------------\n",
      "Question indices for topic Probability_density_function: \n",
      "[39, 45, 49, 60, 61, 62, 63, 64, 67, 68, 72, 73, 77, 79, 83, 85, 87, 89, 93, 95, 97, 98, 100, 101, 103, 107, 108, 111, 112, 114, 116, 117, 118, 119, 122, 124, 128, 130, 135, 138]\n",
      "------------------------------\n",
      "Question indices for topic Taylor_series: \n",
      "[30, 34, 35, 37, 40, 42, 44, 48, 53, 56, 59, 66, 69, 75, 76, 81, 82, 86, 88, 92, 94, 99, 106, 110, 113, 123, 125, 126, 129, 131, 133, 134, 136, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156]\n",
      "------------------------------\n",
      "Question indices for topic Substitution: \n",
      "[31, 32, 33, 36, 38, 41, 43, 46, 47, 50, 51, 52, 54, 55, 57, 58, 65, 70, 71, 72, 74, 78, 80, 84, 90, 91, 96, 102, 104, 105, 109, 115, 120, 121, 127, 132, 137]\n",
      "------------------------------\n",
      "Question indices for topic Lagrange_interpolation: \n",
      "[0, 1]\n",
      "------------------------------\n",
      "Question indices for topic Differentiate: \n",
      "[74, 78, 139, 140, 144, 145]\n",
      "++++++++++++++++++++++++++++++\n",
      "Question indices for topic Integrate: \n",
      "[31, 32, 33, 36, 38, 41, 43, 46, 47, 50, 51, 52, 54, 55, 57, 58, 64, 65, 70, 71, 72, 74, 78, 80, 84, 90, 91, 96, 102, 104, 105, 109, 115, 120, 121, 127, 132, 137]\n",
      "++++++++++++++++++++++++++++++\n",
      "Question indices for topic Linear_algebra: \n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175]\n",
      "++++++++++++++++++++++++++++++\n",
      "Question indices for topic Probability_and_statistics: \n",
      "[39, 45, 49, 60, 61, 62, 63, 64, 67, 68, 72, 73, 77, 79, 83, 85, 87, 89, 93, 95, 97, 98, 100, 101, 103, 107, 108, 111, 112, 114, 116, 117, 118, 119, 122, 124, 128, 130, 135, 138, 166, 171]\n",
      "++++++++++++++++++++++++++++++\n",
      "Question indices for topic Sequences_and_series: \n",
      "[30, 34, 35, 37, 40, 42, 44, 48, 53, 56, 59, 66, 69, 75, 76, 81, 82, 86, 88, 92, 94, 99, 106, 110, 113, 123, 125, 126, 129, 131, 133, 134, 136, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156]\n",
      "++++++++++++++++++++++++++++++\n"
     ]
    }
   ],
   "source": [
    "def question_indices_by_topic(qs, parents=False):\n",
    "    '''\n",
    "    Returns list of the same length as the number of topics (parent topics if parents=True).\n",
    "    Each list contains the indices of the questions qs in this topic (parent topic if parents=True)\n",
    "    '''\n",
    "    if parents:\n",
    "        list_to_match = helpers.unique_parents(qs)\n",
    "    else:\n",
    "        list_to_match = topic_tags\n",
    "\n",
    "    num_sublists = len(list_to_match)\n",
    "    all_indices = [[] for i in range(num_sublists)]\n",
    "    \n",
    "    for i, q in enumerate(qs):\n",
    "        for j, t in enumerate(list_to_match):\n",
    "            if (not parents) and (t in q['topics']):\n",
    "                all_indices[j].append(i)\n",
    "            elif parents and t in helpers.question_to_parents(q):\n",
    "                all_indices[j].append(i)\n",
    "    return all_indices\n",
    "                \n",
    "\n",
    "for i, topic in enumerate(topic_tags):\n",
    "    print \"Question indices for topic %s: \\n\" % topic, question_indices_by_topic(questions_raw)[i]\n",
    "    print \"-\" * 30\n",
    "    \n",
    "for i, topic in enumerate(helpers.unique_parents(questions_raw)):\n",
    "    print \"Question indices for topic %s: \\n\" % topic, question_indices_by_topic(questions_raw, parents=True)[i]\n",
    "    print \"+\" * 30\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Questions picked topics: [21, 135, 146, 50, 0]\n",
      "Questions picked parents: [74, 109, 172, 77, 126]\n"
     ]
    }
   ],
   "source": [
    "# for reproducibility we set the seed of the random number generator\n",
    "np.random.seed(23)\n",
    "\n",
    "def pick_random_index_per_topic(qs, parents=False):\n",
    "    '''Returns a list of randomly chosen question indices - one for each topic (parent topic if parents=True)'''\n",
    "    question_indices = question_indices_by_topic(qs, parents)\n",
    "    result = []\n",
    "    for indices in question_indices:\n",
    "        # pick random index\n",
    "        question_index_for_topic = np.random.choice(indices)\n",
    "        # add to result list, avoiding duplicates in case questions match more than one topic (parent topic if parents=True)\n",
    "        if question_index_for_topic not in result:\n",
    "            result.append(question_index_for_topic)\n",
    "    return result\n",
    "\n",
    "print \"Questions picked topics:\", pick_random_index_per_topic(questions_raw)\n",
    "print \"Questions picked parents:\", pick_random_index_per_topic(questions_raw, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4], [4], [], [5]]\n"
     ]
    }
   ],
   "source": [
    "def remove_from_question_indices(ls, indices_by_topic):\n",
    "    '''Takes a list ls and a list of lists indices_by_topic\n",
    "        and removes all elements of ls from each element of indices_by_topic'''\n",
    "    \n",
    "    for index_list in indices_by_topic:\n",
    "        for element in ls:\n",
    "            if element in index_list:\n",
    "                index_list.remove(element)\n",
    "    \n",
    "    return indices_by_topic\n",
    "\n",
    "#example\n",
    "print(remove_from_question_indices([1, 2, 3], [[1, 2, 4],[4, 3],[],[5]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# helper functions for the train_test_split function\n",
    "\n",
    "def sample_from_class(indices, n):\n",
    "    return np.random.choice(indices, n, replace = False)\n",
    "\n",
    "def sample_from_all_classes(indices_by_topic, num_total_samples, num_questions):\n",
    "    if (num_total_samples <= 0):\n",
    "        return []\n",
    "\n",
    "    sample_indices = set([])\n",
    "    for index_list in indices_by_topic:\n",
    "        if 0 == len(index_list):\n",
    "            # it is possible that all samples from a particular class are \n",
    "            continue\n",
    "        class_proportion = float(len(index_list)) / num_questions\n",
    "        num_class_samples = int(num_total_samples * class_proportion)\n",
    "        class_samples = sample_from_class(index_list, num_class_samples)\n",
    "        # update the set sample_indices with new class samples\n",
    "        sample_indices.update(class_samples)\n",
    "    return list(sample_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question indices for training set:\n",
      "[0, 2, 3, 4, 5, 6, 7, 9, 10, 12, 13, 14, 15, 16, 18, 19, 20, 22, 24, 25, 26, 28, 29, 30, 31, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 46, 47, 49, 50, 52, 53, 55, 56, 57, 58, 59, 60, 62, 63, 65, 66, 67, 68, 71, 73, 74, 75, 76, 78, 79, 80, 82, 83, 85, 86, 87, 88, 89, 90, 92, 96, 97, 100, 101, 102, 103, 105, 107, 108, 109, 110, 111, 112, 113, 114, 115, 117, 118, 120, 122, 123, 125, 126, 127, 129, 130, 131, 132, 133, 134, 135, 137, 138, 140, 141, 142, 143, 144, 145, 149, 150, 151, 152, 153, 155, 156, 158, 160, 162, 163, 165, 167, 168, 169, 170, 171, 172, 174, 175]\n",
      "\n",
      "\n",
      "TRAIN/TEST:\n",
      "##/## - Topic\n",
      "=============\n",
      "35/12 - Eigenvalues and eigenvectors\n",
      "29/11 - Probability density function\n",
      "38/13 - Taylor series\n",
      "27/10 - Substitution\n",
      " 1/ 1 - Lagrange interpolation\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Question indices for training set (parents):\n",
      "[1, 3, 4, 5, 6, 7, 8, 10, 12, 13, 14, 15, 17, 18, 19, 21, 23, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 44, 45, 46, 47, 49, 50, 51, 53, 56, 57, 59, 60, 61, 62, 64, 65, 66, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 93, 94, 95, 96, 99, 101, 102, 105, 107, 109, 110, 111, 112, 113, 114, 116, 117, 120, 121, 122, 125, 126, 127, 128, 130, 131, 132, 133, 135, 136, 137, 138, 139, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 152, 155, 156, 158, 159, 160, 161, 162, 163, 165, 166, 168, 169, 170, 171, 173, 174, 175]\n",
      "\n",
      "\n",
      "TRAIN/TEST:\n",
      "##/## - Topic (Parents)\n",
      "=============\n",
      " 4/ 2 - Differentiate\n",
      "29/ 9 - Integrate\n",
      "36/13 - Linear algebra\n",
      "32/10 - Probability and statistics\n",
      "38/13 - Sequences and series\n"
     ]
    }
   ],
   "source": [
    "#np.random.seed(23)  #Set seed back to 23 to see the problem when a topic has no question in test set\n",
    "np.random.seed(22)\n",
    "\n",
    "def train_test_split(qs, TRAIN_PROPORTION=0.75, parents=False):\n",
    "    '''randomly splits list of questions into two lists for train and test'''\n",
    "    TRAIN_SIZE = int(TRAIN_PROPORTION * len(qs))\n",
    "                        \n",
    "    # pick a question from each topic (parent topic if parents=True) and add to training set\n",
    "    indices_from_each_topic = pick_random_index_per_topic(qs, parents)\n",
    "    \n",
    "    # from the rest of the questions, pick indices from each class according to topic probabilities:\n",
    "    indices_left = remove_from_question_indices(indices_from_each_topic, question_indices_by_topic(qs, parents))\n",
    "        \n",
    "    samples_left_to_take = TRAIN_SIZE - len(indices_from_each_topic)\n",
    "    \n",
    "    randomly_picked_indices = sample_from_all_classes(indices_left, \n",
    "                                                      samples_left_to_take, \n",
    "                                                      len(qs) - len(indices_from_each_topic))\n",
    "    \n",
    "    train_indices = sorted(indices_from_each_topic + randomly_picked_indices)\n",
    "    \n",
    "   \n",
    "    qs_train = [q for i, q in enumerate(qs) if i in train_indices]\n",
    "    qs_test = [q for i, q in enumerate(qs) if not i in train_indices]\n",
    "    \n",
    "    #permuted = np.random.permutation(len(qs_train))\n",
    "    #qs_train_permuted = [qs_train[i] for i in permuted]\n",
    "    #!!!\n",
    "    return qs_train, qs_test, train_indices\n",
    "\n",
    "questions_train, questions_test, train_indices = train_test_split(questions_raw, parents=False)\n",
    "\n",
    "print(\"Question indices for training set:\")\n",
    "print(train_indices)\n",
    "print(\"\\n\")\n",
    "assert (questions_train[train_indices.index(3)]['sols_raw'] == questions_raw[3]['sols_raw'])\n",
    "\n",
    "\n",
    "print('TRAIN/TEST:\\n##/## - Topic\\n=============')\n",
    "for t in topic_tags:\n",
    "    print('%2d/%2d - %s' % (sum([1 for q in questions_train if t in q['topics']]),\n",
    "                          sum([1 for q in questions_test if t in q['topics']]),\n",
    "                          t.replace('_', ' ')))    \n",
    "\n",
    "\n",
    "print('\\n' * 5)\n",
    "\n",
    "questions_train, questions_test, train_indices = train_test_split(questions_raw, parents=True)\n",
    "\n",
    "print(\"Question indices for training set (parents):\")\n",
    "print(train_indices)\n",
    "print(\"\\n\")\n",
    "\n",
    "print('TRAIN/TEST:\\n##/## - Topic (Parents)\\n=============')\n",
    "for t in helpers.unique_parents(questions_train):\n",
    "    print('%2d/%2d - %s' % (sum([1 for q in questions_train if t in helpers.question_to_parents(q)]),\n",
    "                          sum([1 for q in questions_test if t in helpers.question_to_parents(q)]),\n",
    "                          t.replace('_', ' ')))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 0 0 1]\n",
      " [0 1 0 0 0]\n",
      " [0 1 0 0 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 0 0 1]\n",
      " [0 0 0 0 1]\n",
      " [0 1 0 0 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 0 1 0]\n",
      " [0 0 0 0 1]\n",
      " [0 0 0 0 1]\n",
      " [0 0 0 1 0]\n",
      " [0 1 0 0 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 0 1 0]\n",
      " [0 1 0 0 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 0 0 1]\n",
      " [0 0 0 0 1]\n",
      " [0 1 0 0 0]\n",
      " [0 0 0 0 1]\n",
      " [0 0 0 1 0]\n",
      " [0 0 0 1 0]\n",
      " [0 0 0 1 0]\n",
      " [0 1 0 0 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 0 0 1]\n",
      " [0 0 0 1 0]\n",
      " [0 0 0 0 1]\n",
      " [0 1 0 0 0]\n",
      " [0 1 0 0 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 0 1 0]\n",
      " [0 0 0 0 1]\n",
      " [0 0 0 0 1]\n",
      " [0 0 0 1 0]\n",
      " [1 0 0 0 0]\n",
      " [0 0 0 1 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 0 0 1]\n",
      " [0 0 0 1 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 0 1 0]\n",
      " [0 0 0 0 1]\n",
      " [0 0 0 1 0]\n",
      " [0 0 0 0 1]\n",
      " [0 0 0 1 0]\n",
      " [0 1 0 0 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 0 1 0]\n",
      " [0 0 0 0 1]\n",
      " [0 0 0 1 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 0 0 1]\n",
      " [0 0 0 1 0]\n",
      " [0 1 0 0 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 0 1 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 0 0 1]\n",
      " [0 0 0 1 0]\n",
      " [0 0 0 1 0]\n",
      " [0 0 0 0 1]\n",
      " [0 0 0 1 0]\n",
      " [0 0 0 1 0]\n",
      " [0 0 0 1 0]\n",
      " [0 1 0 0 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 0 1 0]\n",
      " [0 0 0 0 1]\n",
      " [0 0 0 0 1]\n",
      " [0 1 0 0 0]\n",
      " [0 0 0 1 0]\n",
      " [0 0 0 1 0]\n",
      " [0 0 0 0 1]\n",
      " [0 1 0 0 0]\n",
      " [0 0 0 0 1]\n",
      " [0 0 0 1 0]\n",
      " [0 0 0 0 1]\n",
      " [0 1 0 0 0]\n",
      " [0 0 0 1 0]\n",
      " [1 0 0 0 0]\n",
      " [0 0 0 0 1]\n",
      " [0 0 0 0 1]\n",
      " [0 0 0 0 1]\n",
      " [1 0 0 0 0]\n",
      " [1 0 0 0 0]\n",
      " [0 0 0 0 1]\n",
      " [0 0 0 0 1]\n",
      " [0 0 0 0 1]\n",
      " [0 0 0 0 1]\n",
      " [0 0 0 0 1]\n",
      " [0 0 0 0 1]\n",
      " [0 0 0 0 1]\n",
      " [0 0 0 0 1]\n",
      " [0 0 1 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "vectorizer = helpers.save_TfidfVectorizer(questions_train)\n",
    "\n",
    "X_train = helpers.questions_to_X(questions_train)\n",
    "X_test = helpers.questions_to_X(questions_test)\n",
    "assert X_train.shape[0] == len(questions_train)\n",
    "\n",
    "y_train = helpers.questions_to_y(questions_train, helpers.unique_parents(questions_train), parents=True)\n",
    "y_test = helpers.questions_to_y(questions_test, helpers.unique_parents(questions_train), parents=True)\n",
    "assert len(y_train) == len(questions_train)\n",
    "\n",
    "\n",
    "#!!!\n",
    "print(y_train)\n",
    "train_labels = helpers.questions_to_topic_index(questions_train, helpers.unique_parents(questions_train))\n",
    "test_labels = helpers.questions_to_topic_index(questions_test, helpers.unique_parents(questions_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The actual classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# SVC for now\n",
    "classifier = OneVsRestClassifier(svm.SVC(kernel='linear',\n",
    "                                         probability = True,\n",
    "                                         random_state=np.random.RandomState(0))\n",
    " \n",
    "                                )\n",
    "\n",
    "\n",
    "trained_classifier = classifier.fit(X_train, y_train)\n",
    "pickle.dump(trained_classifier, open(\"svc.bin\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequences_and_series\n",
      "Linear_algebra\n",
      "Linear_algebra\n",
      "Linear_algebra\n",
      "Linear_algebra\n",
      "Linear_algebra\n",
      "Linear_algebra\n",
      "Linear_algebra\n",
      "Linear_algebra\n",
      "Sequences_and_series\n",
      "Integrate\n",
      "Sequences_and_series\n",
      "Integrate\n",
      "Sequences_and_series\n",
      "Integrate\n",
      "Integrate\n",
      "Integrate\n",
      "Integrate\n",
      "Probability_and_statistics\n",
      "Probability_and_statistics\n",
      "Integrate\n",
      "Sequences_and_series\n",
      "Sequences_and_series\n",
      "Probability_and_statistics\n",
      "Probability_and_statistics\n",
      "Probability_and_statistics\n",
      "Probability_and_statistics\n",
      "Integrate\n",
      "Sequences_and_series\n",
      "Probability_and_statistics\n",
      "Integrate\n",
      "Probability_and_statistics\n",
      "Probability_and_statistics\n",
      "Sequences_and_series\n",
      "Probability_and_statistics\n",
      "Sequences_and_series\n",
      "Sequences_and_series\n",
      "Differentiate\n",
      "Sequences_and_series\n",
      "Sequences_and_series\n",
      "Sequences_and_series\n",
      "Linear_algebra\n",
      "Linear_algebra\n",
      "Linear_algebra\n",
      "Linear_algebra\n"
     ]
    }
   ],
   "source": [
    "preds = trained_classifier.predict_proba(X_test)\n",
    "predicted_classes = helpers.preds_to_topics(preds, helpers.unique_parents(questions_train))\n",
    "\n",
    "print('\\n'.join(predicted_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# To visualize the problem with auc when a topic has no question in test set\n",
    "#from sklearn.metrics import roc_curve, auc\n",
    "#print('these numbers should all be the same:', y_train.shape[1], y_test.shape[1], preds.shape[1])\n",
    "#fpr = dict()\n",
    "#tpr = dict()\n",
    "#roc_auc = dict()\n",
    "#for i in range(preds.shape[1]):\n",
    "#    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], preds[:, i])\n",
    "#    roc_auc[i] = auc(fpr[i], tpr[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99704 combined micro AUC score.\n"
     ]
    }
   ],
   "source": [
    "print('%.5f combined micro AUC score.' %helpers.combined_roc_score(y_test, preds)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize (todo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=3)\n",
    "pca.fit(X_train.toarray())\n",
    "pca_X_train = pca.transform(X_train.toarray())\n",
    "pca_X_test = pca.transform(X_test.toarray())\n",
    "print('The first 3 principal components explain %.2f of the variance in the dataset.' % sum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(23)\n",
    "fig = plt.figure(1, figsize=(8, 6))\n",
    "plt.clf()\n",
    "ax = Axes3D(fig, rect=[0, 0, .8, 1], elev=25, azim=70)\n",
    "\n",
    "colors = [np.random.rand(3,1) for i in range(len(topic_tags))]\n",
    "\n",
    "for i, l in zip(range(len(topic_tags)), train_labels):\n",
    "    ax.scatter(pca_X_train[train_labels == i,0],\n",
    "           pca_X_train[train_labels == i,1],\n",
    "           pca_X_train[train_labels == i,2], c=colors[i], label = topic_tags[i] + ' (train)')\n",
    " \n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig2 = plt.figure(1, figsize=(8, 6))\n",
    "plt.clf()\n",
    "ax2 = Axes3D(fig2, rect=[0, 0, .8, 1], elev=25, azim=70)\n",
    "for i, l in zip(range(len(topic_tags)), test_labels):\n",
    "    ax2.scatter(pca_X_train[test_labels == i,0],\n",
    "           pca_X_train[test_labels == i,1],\n",
    "           pca_X_train[test_labels == i,2], c=colors[i], label = topic_tags[i] + ' (test)', marker = 'x')   \n",
    " \n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this is moved to helpers\n",
    "def predict_topic_for_question(q, classifier):\n",
    "    vec = helpers.question_to_X(q)\n",
    "    pred_prob = classifier.predict_proba(vec)\n",
    "    pred_class = helpers.pred_to_topic(pred_prob, topic_tags)\n",
    "    \n",
    "    return pred_class\n",
    "\n",
    "def determine_topic_for_question(q, classifier):\n",
    "    # assumes only one topic\n",
    "    if q == None:\n",
    "        return None\n",
    "    try:\n",
    "        for t in topic_tags:\n",
    "            if t in q['topics']:\n",
    "                return t\n",
    "    except KeyError:\n",
    "        pass\n",
    "    predicted = predict_topic_for_question(q, classifier)\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predicting using the entire dataset:\n",
    "\n",
    "X = helpers.questions_to_X(questions_raw)\n",
    "y = helpers.questions_to_y(questions_raw, topic_tags)\n",
    "\n",
    "final_classifier = classifier.fit(X, y)\n",
    "\n",
    "#!!!\n",
    "pickle.dump(final_classifier, open(\"test_sending_json/final.bin\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(helpers.determine_topic_for_question(questions_raw[77], trained_classifier, topic_tags).replace(\"_\", \" \"))\n",
    "print(questions_raw[77]['topics'])\n",
    "\n",
    "\n",
    "\n",
    "client = MongoClient()\n",
    "random_question = client['merdb'].questions.find_one()\n",
    "\n",
    "print(helpers.determine_topic_for_question(random_question, final_classifier, topic_tags))\n",
    "print(random_question.keys())\n",
    "print(random_question['statement_html'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
