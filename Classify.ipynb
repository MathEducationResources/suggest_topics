{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict the topic of a Math Question on Math Education Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use **Machine Learning** to predict the topic of a Math Question from the [Math Education Resources](http://math-education-resources.com). For simplicity we will only consider two topics. Using [multiclass classification](https://en.wikipedia.org/wiki/Multiclass_classification) this can be extended to more than two topics (at the time of writing, April 2015, we have about 1500 questions with 150 topics on MER)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "client = MongoClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'ID': u'UBC+MATH307+April_2012+01_(d)',\n",
       " u'_id': ObjectId('55383310cec2a2367cebc622'),\n",
       " u'answer_html': u'<p>No content found.</p>',\n",
       " u'answer_latex': u'No content found.',\n",
       " u'contributors': [u'Konradbe'],\n",
       " u'course': u'MATH307',\n",
       " u'flags': [u'RQ', u'CH', u'CS', u'CT'],\n",
       " u'hints_html': [u'<p>No content found.</p>'],\n",
       " u'hints_latex': [u'No content found.'],\n",
       " u'hints_raw': [u'No content found.'],\n",
       " u'num_votes': 0,\n",
       " u'question': u'1 (d)',\n",
       " u'rating': -1,\n",
       " u'sols_html': [u'<p>No content found.</p>'],\n",
       " u'sols_latex': [u'No content found.'],\n",
       " u'sols_raw': [u'No content found.'],\n",
       " u'statement_html': u'<p>Suppose you are given a set of <em>N</em> data points <em>(x<sub>n</sub>, y<sub>n</sub>)</em>, with <em>x<sub>n</sub></em> increasing, and you wish to interpolate these points with a spline function <em><span class=\"math\">\\\\(f\\\\)</span></em>, where <em><span class=\"math\">\\\\(f\\\\)</span>(x)</em> is given by the cubic polynomial <em>p<sub>n</sub>(x)</em> on each interval <em>(x<sub>n</sub>, x<sub>n+1</sub>)</em> for <em>n = 1, ..., N-1</em>:</p>\\n<p><span class=\"math\">\\\\[\\\\begin{aligned}\\n\\\\displaystyle\\np_n(x) = a_n(x-x_n)^3 + b_n(x-x_n)^2 + c_n(x-x_n) + d_n\\\\end{aligned}\\\\]</span></p>\\n<p><strong>(d)</strong> Write down the matrix equation to be solved for the coefficients of the polynomials in the case <em>N = 3</em>, with <em>x<sub>1</sub> = 1</em>, <em>x<sub>2</sub> = 2</em>, <em>x<sub>3</sub> = 3</em>.</p>',\n",
       " u'statement_latex': u'Suppose you are given a set of \\\\emph{N} data points\\n\\\\emph{(x\\\\textsubscript{n}, y\\\\textsubscript{n})}, with\\n\\\\emph{x\\\\textsubscript{n}} increasing, and you wish to interpolate these\\npoints with a spline function \\\\emph{$f$}, where \\\\emph{$f$(x)} is given by\\nthe cubic polynomial \\\\emph{p\\\\textsubscript{n}(x)} on each interval\\n\\\\emph{(x\\\\textsubscript{n}, x\\\\textsubscript{n+1})} for \\\\emph{n = 1, ...,\\nN-1}:\\n\\n\\\\begin{align*}\\n\\\\displaystyle\\np_n(x) = a_n(x-x_n)^3 + b_n(x-x_n)^2 + c_n(x-x_n) + d_n\\n\\\\end{align*}\\n\\n\\\\textbf{(d)} Write down the matrix equation to be solved for the\\ncoefficients of the polynomials in the case \\\\emph{N = 3}, with\\n\\\\emph{x\\\\textsubscript{1} = 1}, \\\\emph{x\\\\textsubscript{2} = 2},\\n\\\\emph{x\\\\textsubscript{3} = 3}.',\n",
       " u'statement_raw': u\"Suppose you are given a set of ''N'' data points ''(x&lt;sub>n&lt;/sub>, y&lt;sub>n&lt;/sub>)'', with ''x&lt;sub>n&lt;/sub>'' increasing, and you wish to interpolate these points with a spline function ''&amp;fnof;'', where ''&amp;fnof;(x)'' is given by the cubic polynomial ''p&lt;sub>n&lt;/sub>(x)'' on each interval ''(x&lt;sub>n&lt;/sub>, x&lt;sub>n+1&lt;/sub>)'' for ''n = 1, ..., N-1'':\\n\\n:&lt;math> \\\\displaystyle\\np_n(x) = a_n(x-x_n)^3 + b_n(x-x_n)^2 + c_n(x-x_n) + d_n\\n&lt;/math>\\n\\n'''(d)''' Write down the matrix equation to be solved for the coefficients of the polynomials in the case ''N = 3'', with ''x&lt;sub>1&lt;/sub> = 1'', ''x&lt;sub>2&lt;/sub> = 2'', ''x&lt;sub>3&lt;/sub> = 3''.\",\n",
       " u'term': u'April',\n",
       " u'url': u'http://wiki.ubc.ca/Science:Math_Exam_Resources/Courses/MATH307/April_2012/Question_01_(d)',\n",
       " u'year': 2012}"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions_collection = client['merdb'].questions\n",
    "\n",
    "\n",
    "questions_collection.find_one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create an array of all topics of interest\n",
    "\n",
    "topic_tags = [\"Eigenvalues_and_eigenvectors\", \"Probability_density_function\", \"Taylor_series\", \"Substitution\"]\n",
    "\n",
    "num_classes = len(topic_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create an array of questions with topics contained in topic_tags\n",
    "\n",
    "questions = []\n",
    "for q in questions_collection.find({\"topics\": \n",
    "                                         {\"$in\": topic_tags}\n",
    "                                        }):\n",
    "    questions.append(q)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Eigenvalues_and_eigenvectors', 45)\n",
      "('Probability_density_function', 39)\n",
      "('Taylor_series', 50)\n",
      "('Substitution', 37)\n"
     ]
    }
   ],
   "source": [
    "# count how many questions there are for each topic in topic_tags\n",
    "\n",
    "for t in topic_tags:\n",
    "    print(t, questions_collection.find({\"topics\": t}).count())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'rating',\n",
       " u'contributors',\n",
       " u'topics',\n",
       " u'year',\n",
       " u'answer_html',\n",
       " u'course',\n",
       " u'solvers',\n",
       " u'sols_raw',\n",
       " u'hints_html',\n",
       " u'question',\n",
       " u'statement_raw',\n",
       " u'num_votes',\n",
       " u'statement_html',\n",
       " u'term',\n",
       " u'statement_latex',\n",
       " u'hints_raw',\n",
       " u'hints_latex',\n",
       " u'ID',\n",
       " u'sols_latex',\n",
       " u'url',\n",
       " u'flags',\n",
       " u'answer_latex',\n",
       " u'sols_html',\n",
       " u'_id']"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions[77].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data preprocessing modules\n",
    "\n",
    "import helpers\n",
    "from nltk import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.preprocessing import label_binarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigenvalues_and_eigenvectors questions in test set: 30\n",
      "Probability_density_function questions in test set: 32\n",
      "Taylor_series questions in test set: 40\n",
      "Substitution questions in test set: 26\n"
     ]
    }
   ],
   "source": [
    "# split the questions into training and test\n",
    "\n",
    "\n",
    "# for reproducibility we set the seed of the random number generator\n",
    "np.random.seed(23)\n",
    "\n",
    "test_proportion = 0.75\n",
    "num_samples = int(test_proportion * len(questions))\n",
    "test_indices = np.random.choice(range(len(questions)), num_samples, replace=False)\n",
    "\n",
    "\n",
    "questions_train = [q for i, q in enumerate(questions) if not i in test_indices]\n",
    "questions_test = [q for i, q in enumerate(questions) if i in test_indices]\n",
    "\n",
    "for topic in topic_tags:\n",
    "    print('%s questions in test set: %d' % (topic, sum([1 for q in questions_test if topic in q['topics']])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# clean & filter data\n",
    "def words_from_question(q):\n",
    "    # we are only interested in question statement, hints and solution\n",
    "    all_text = q['statement_html'] + q['hints_html'][0] + q['sols_html'][0] \n",
    "    return helpers.strip_text(all_text)\n",
    "\n",
    "# remove commonly used words and combine words with the same root\n",
    "def words_stemmed_no_stop(words):\n",
    "    stop = stopwords.words('english')\n",
    "    res = []\n",
    "    for word in words:\n",
    "        stemmed = PorterStemmer().stem_word(word)\n",
    "        if stemmed not in stop and len(stemmed) > 1: #take words longer than 1 char\n",
    "            res.append(stemmed)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Number of distinct words:', 462)\n",
      "[u'abov', u'accord', u'ad', u'addit', u'age', u'ahead', u'allow', u'almost', u'also', u'altern', u'alway', u'analyt', u'ani', u'anoth', u'answer']\n"
     ]
    }
   ],
   "source": [
    "# collect all stemmed words from training set, excluding stop words\n",
    "\n",
    "vocabulary = []\n",
    "\n",
    "for q in questions_train:\n",
    "    vocabulary += words_stemmed_no_stop(words_from_question(q))\n",
    "vocabulary_sorted = sorted(set(vocabulary))\n",
    "\n",
    "\n",
    "\n",
    "print('Number of distinct words:', len(vocabulary_sorted))\n",
    "print(vocabulary_sorted[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# returns a binary vector for a question, indicating whether a word\n",
    "# from vocabulary is contained in the question\n",
    "\n",
    "def question_to_vector(q, voc):\n",
    "    # vector of dimension 1xlen(voc)\n",
    "    x_vec = np.zeros(len(voc))\n",
    "    words = words_stemmed_no_stop(words_from_question(q))\n",
    "    for word in words:\n",
    "        if word in voc:\n",
    "            x_vec[voc.index(word)] = 1\n",
    "    return x_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  1.  1. ...,  0.  0.  0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "24.0"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(question_to_vector(questions[0], vocabulary))\n",
    "sum(question_to_vector(questions[0], vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create an array of numerical labels for classes\n",
    "\n",
    "class_indices = range(0, num_classes)\n",
    "\n",
    "# transform questions into appropriate labels\n",
    "def questions_to_y(qs):\n",
    "    topic_labels = []\n",
    "    for q in qs:\n",
    "        # go through topic_tags, if any of the topics is in the question's topic list\n",
    "        # append its index to topic_labels\n",
    "        for i in class_indices:\n",
    "            if topic_tags[i] in q['topics']:\n",
    "                topic_labels.append(i)\n",
    "                # assumes there is only one topic for each question\n",
    "                break \n",
    "                \n",
    "    return label_binarize(topic_labels, class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def questions_to_X(qs, voc):\n",
    "    X = np.zeros(shape=(len(qs), len(voc)))\n",
    "\n",
    "    for i, q in enumerate(qs):\n",
    "        X[i, :] = question_to_vector(q, voc)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = questions_to_X(questions_train, vocabulary_sorted)\n",
    "X_test = questions_to_X(questions_test, vocabulary_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert len(X_train) == len(questions_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train = questions_to_y(questions_train)\n",
    "y_test = questions_to_y(questions_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# machine learning modules\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# SVM classifier\n",
    "\n",
    "classifier = OneVsRestClassifier(svm.SVC(kernel='linear', probability = True, random_state=np.random.RandomState(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trained_classifier = classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.743  0.038  0.037  0.04 ]\n",
      " [ 0.823  0.093  0.08   0.003]\n",
      " [ 0.827  0.087  0.022  0.01 ]\n",
      " [ 0.839  0.103  0.013  0.012]\n",
      " [ 0.978  0.025  0.003  0.006]\n",
      " [ 0.96   0.067  0.011  0.003]\n",
      " [ 0.994  0.04   0.025  0.   ]\n",
      " [ 0.981  0.049  0.017  0.002]\n",
      " [ 0.979  0.011  0.156  0.001]\n",
      " [ 0.875  0.12   0.024  0.004]\n",
      " [ 0.95   0.02   0.023  0.007]\n",
      " [ 0.98   0.055  0.01   0.002]\n",
      " [ 0.562  0.054  0.113  0.029]\n",
      " [ 0.858  0.065  0.027  0.012]\n",
      " [ 0.988  0.013  0.005  0.008]\n",
      " [ 0.992  0.023  0.016  0.001]\n",
      " [ 0.991  0.015  0.041  0.001]\n",
      " [ 0.917  0.023  0.014  0.027]\n",
      " [ 0.838  0.055  0.655  0.001]\n",
      " [ 0.042  0.131  0.948  0.014]\n",
      " [ 0.008  0.039  0.009  0.991]\n",
      " [ 0.03   0.022  0.011  0.961]\n",
      " [ 0.038  0.247  0.969  0.005]\n",
      " [ 0.018  0.044  0.007  0.977]\n",
      " [ 0.032  0.936  0.028  0.017]\n",
      " [ 0.048  0.027  1.     0.003]\n",
      " [ 0.015  0.024  1.     0.012]\n",
      " [ 0.009  0.951  0.065  0.043]\n",
      " [ 0.024  0.04   0.008  0.971]\n",
      " [ 0.05   0.047  0.001  0.985]\n",
      " [ 0.022  0.039  0.995  0.025]\n",
      " [ 0.033  0.979  0.013  0.01 ]\n",
      " [ 0.012  0.021  0.004  0.993]\n",
      " [ 0.04   0.064  0.891  0.035]\n",
      " [ 0.043  0.022  0.002  0.988]\n",
      " [ 0.031  0.032  0.004  0.985]\n",
      " [ 0.039  0.063  0.964  0.031]\n",
      " [ 0.002  0.032  0.008  1.   ]\n",
      " [ 0.001  0.768  0.107  0.608]\n",
      " [ 0.001  0.99   0.004  0.431]\n",
      " [ 0.034  0.862  0.347  0.007]\n",
      " [ 0.007  0.988  0.019  0.019]\n",
      " [ 0.057  0.117  0.067  0.371]\n",
      " [ 0.03   0.133  0.79   0.068]\n",
      " [ 0.045  0.934  0.06   0.01 ]\n",
      " [ 0.025  0.037  0.99   0.025]\n",
      " [ 0.052  0.153  0.006  0.788]\n",
      " [ 0.08   0.061  0.175  0.331]\n",
      " [ 0.018  0.615  0.22   0.052]\n",
      " [ 0.012  0.468  0.154  0.248]\n",
      " [ 0.012  0.047  0.056  0.929]\n",
      " [ 0.03   0.023  0.982  0.038]\n",
      " [ 0.014  0.062  0.988  0.034]\n",
      " [ 0.009  0.795  0.152  0.069]\n",
      " [ 0.011  0.035  0.012  0.987]\n",
      " [ 0.057  0.844  0.005  0.125]\n",
      " [ 0.052  0.034  0.023  0.881]\n",
      " [ 0.057  0.097  0.995  0.002]\n",
      " [ 0.025  0.958  0.013  0.03 ]\n",
      " [ 0.025  0.037  0.006  0.98 ]\n",
      " [ 0.013  0.106  0.997  0.009]\n",
      " [ 0.012  0.995  0.028  0.009]\n",
      " [ 0.064  0.061  0.945  0.01 ]\n",
      " [ 0.019  0.994  0.005  0.018]\n",
      " [ 0.049  0.051  0.034  0.797]\n",
      " [ 0.006  0.017  0.531  0.834]\n",
      " [ 0.004  0.019  1.     0.058]\n",
      " [ 0.012  0.959  0.002  0.394]\n",
      " [ 0.005  0.99   0.184  0.011]\n",
      " [ 0.023  0.844  0.076  0.059]\n",
      " [ 0.02   0.175  1.     0.001]\n",
      " [ 0.003  0.928  0.416  0.063]\n",
      " [ 0.016  0.054  0.015  0.958]\n",
      " [ 0.036  0.922  0.007  0.063]\n",
      " [ 0.02   0.043  0.006  0.951]\n",
      " [ 0.006  0.021  1.     0.008]\n",
      " [ 0.023  0.955  0.179  0.008]\n",
      " [ 0.012  0.97   0.004  0.135]\n",
      " [ 0.009  0.015  0.007  0.995]\n",
      " [ 0.017  0.026  0.899  0.219]\n",
      " [ 0.027  0.761  0.019  0.187]\n",
      " [ 0.029  0.815  0.166  0.022]\n",
      " [ 0.052  0.045  0.968  0.015]\n",
      " [ 0.008  0.022  0.004  0.997]\n",
      " [ 0.01   0.99   0.016  0.035]\n",
      " [ 0.03   0.978  0.252  0.001]\n",
      " [ 0.083  0.941  0.025  0.01 ]\n",
      " [ 0.013  0.11   0.027  0.919]\n",
      " [ 0.01   0.976  0.034  0.043]\n",
      " [ 0.005  0.108  1.     0.009]\n",
      " [ 0.054  0.826  0.095  0.018]\n",
      " [ 0.009  0.072  0.997  0.019]\n",
      " [ 0.019  0.031  0.006  0.987]\n",
      " [ 0.007  0.192  0.98   0.044]\n",
      " [ 0.064  0.825  0.083  0.021]\n",
      " [ 0.046  0.216  0.946  0.009]\n",
      " [ 0.018  0.026  0.967  0.153]\n",
      " [ 0.138  0.319  0.119  0.047]\n",
      " [ 0.112  0.039  0.947  0.018]\n",
      " [ 0.033  0.024  0.22   0.755]\n",
      " [ 0.207  0.134  0.096  0.09 ]\n",
      " [ 0.092  0.153  0.297  0.054]\n",
      " [ 0.079  0.156  0.535  0.037]\n",
      " [ 0.04   0.158  0.665  0.06 ]\n",
      " [ 0.031  0.098  0.974  0.02 ]\n",
      " [ 0.049  0.112  0.5    0.086]\n",
      " [ 0.136  0.089  0.973  0.003]\n",
      " [ 0.037  0.058  0.995  0.007]\n",
      " [ 0.136  0.131  0.591  0.022]\n",
      " [ 0.014  0.069  0.992  0.009]\n",
      " [ 0.119  0.078  0.834  0.015]\n",
      " [ 0.002  0.38   1.     0.006]\n",
      " [ 0.033  0.071  0.873  0.067]\n",
      " [ 0.076  0.021  0.785  0.098]\n",
      " [ 0.077  0.053  0.79   0.052]\n",
      " [ 0.011  0.104  1.     0.004]\n",
      " [ 0.969  0.026  0.006  0.01 ]\n",
      " [ 0.913  0.007  0.014  0.056]\n",
      " [ 0.964  0.031  0.03   0.004]\n",
      " [ 0.971  0.015  0.017  0.005]\n",
      " [ 0.956  0.031  0.003  0.031]\n",
      " [ 0.345  0.024  0.127  0.091]\n",
      " [ 0.968  0.056  0.002  0.009]\n",
      " [ 0.982  0.116  0.001  0.003]\n",
      " [ 0.305  0.114  0.196  0.019]\n",
      " [ 0.973  0.014  0.013  0.008]\n",
      " [ 0.926  0.034  0.017  0.016]]\n"
     ]
    }
   ],
   "source": [
    "preds = trained_classifier.predict_proba(X_test)\n",
    "\n",
    "print(np.around(preds, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 1 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-311-104dbc60b1f7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mfpr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mroc_auc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mauc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 1 is out of bounds for axis 1 with size 1"
     ]
    }
   ],
   "source": [
    "# code not edited\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "for i in range(3):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], preds[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), preds.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "print(roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
